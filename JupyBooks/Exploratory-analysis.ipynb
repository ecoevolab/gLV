{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eef6c753",
   "metadata": {},
   "source": [
    "## Exploratory data analysis\n",
    "\n",
    "This code performs an exploratory data analysis of the metrics calculated from the extinction events. The analyzed metrics include:\n",
    "\n",
    "* Number of new extinctions (new_ext)\n",
    "\n",
    "* Bray–Curtis dissimilarity (BC_diss)\n",
    "\n",
    "* Keystoneness (K_s)\n",
    "\n",
    "* Time to stability after extinctions (ext_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Section: Generate-paths\n",
    "exp_dir = \"/mnt/data/sur/users/mrivera/Train-sims/4379fd40-9f0a\"\n",
    "tgt_dir = os.path.join(exp_dir, \"GNN-targets\")\n",
    "data_path = os.path.join(exp_dir, \"parameters-sims.tsv\")\n",
    "\n",
    "#  Load-data\n",
    "data = pd.read_csv(data_path, sep=\"\\t\")\n",
    "ids20 = data.loc[data['n_species'] == 20]['id']\n",
    "ids100 = data.loc[data['n_species'] == 100]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aadfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyarrow.feather as ft\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "TGT_DIR = '/mnt/data/sur/users/mrivera/Train-sims/4379fd40-9f0a/GNN-targets'  # Replace with actual path\n",
    "RAW_ODES_DIR = '/mnt/data/sur/users/mrivera/Train-sims/4379fd40-9f0a/raw-ODEs'\n",
    "\n",
    "def read_data(id):\n",
    "    # Load targets\n",
    "    x = ft.read_table(os.path.join(TGT_DIR, f'tgt_{id}.feather'))\n",
    "    ext = x['new_ext'].to_numpy()\n",
    "    Bc = np.round(x['BC_diss'].to_numpy(), 5)\n",
    "    Ks = np.round(x['K_s'].to_numpy(), 5)\n",
    "    # Load relative frequency\n",
    "    y = ft.read_table(os.path.join(RAW_ODES_DIR, f'O_{id}.feather'))\n",
    "    freq = y.column(-1).to_numpy()\n",
    "    # Calculate relative frequency \n",
    "    freq_sum = freq.sum()\n",
    "    rel = freq / freq_sum if freq_sum != 0 else np.zeros_like(freq)\n",
    "    return ext, Bc, Ks, rel\n",
    "\n",
    "\n",
    "def par_dat(ids, max_workers=8):\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(read_data, ids))\n",
    "    # Unpack and convert to numpy arrays\n",
    "    ext, Bc, Ks, rel= map(np.array, zip(*results))\n",
    "    # Flatten/concatenate the vectors\n",
    "    keys = ['extinctions', 'bray_curtis', 'keystone', 'relative']\n",
    "    data = {k: np.concatenate(v) for k, v in zip(keys, [ext, Bc, Ks, rel])}\n",
    "    return data\n",
    "     \n",
    "        \n",
    "# 20 (specs)* Number of simulations with 20 species\n",
    "data20 = par_dat(ids=ids20)\n",
    "data100 = par_dat(ids=ids100)\n",
    "\n",
    "# Test for lengths\n",
    "for key, value in data100.items():\n",
    "    print(f\"{key}: {len(value)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ac8814",
   "metadata": {},
   "source": [
    "# Relative frequencies distribution\n",
    "\n",
    "Generate a plot for relative frequencies distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f5b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# srun --partition=interactive --time=00:40:00 --cpus-per-task=8 --mem=20G --pty bash\n",
    "x1 = data20['relative']\n",
    "x2 = data100['relative']\n",
    "\n",
    "b1 = np.linspace(0, 1, 100)\n",
    "ct1, _ = np.histogram(x1, bins=100)\n",
    "ct2, _ = np.histogram(x2, bins=100)\n",
    "\n",
    "# Apply log\n",
    "ct1_log = np.log1p(ct1) \n",
    "ct2_log = np.log1p(ct2) \n",
    "\n",
    "# Plot distribution\n",
    "plt.clf()  # Clear the entire figure\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(b1, ct1_log, marker='o', linestyle='-', color='blue')\n",
    "plt.plot(b1, ct2_log, marker='o', linestyle='-', color='red')\n",
    "plt.xlabel('Relative frequencies')\n",
    "plt.ylabel('log(Frequency + 1)')\n",
    "plt.title('Distribution of relative frequencies')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/mnt/data/sur/users/mrivera/Plots/RelFreq-distr.png', dpi=300)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20db5beb",
   "metadata": {},
   "source": [
    "## Extinctions distribution\n",
    "We generate a function to compare the distribution of the number of extinctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e202bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate counting \n",
    "labels20, counts20 = np.unique(ext20, return_counts=True)\n",
    "labels100, counts100 = np.unique(ext100, return_counts=True)\n",
    "\n",
    "def pie_dat(labels, counts):\n",
    "    # Filter by >5% of data\n",
    "    rel = counts/sum(counts)\n",
    "    labels_final, counts_final, fail_counts = labels[rel > 0.05],  counts[rel > 0.05], counts[rel <= 0.05].sum()\n",
    "    # Pie chart final labels and counts\n",
    "    pie_labels= np.append(labels_final, 'other')\n",
    "    pie_counts= np.append(counts_final, fail_counts)\n",
    "    return pie_counts, pie_labels\n",
    "\n",
    "# Generate pie chart data\n",
    "pie_20, pie_labels20 = pie_dat(labels = labels20, counts = counts20)\n",
    "pie_100, pie_labels100 = pie_dat(labels = labels100, counts = counts100)\n",
    "\n",
    "# Generate the pie chart\n",
    "plt.clf()  # Clear the entire figure\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "colors = sns.color_palette('pastel')\n",
    "\n",
    "# First pie chart\n",
    "ax1.pie(pie_20, labels = pie_labels20, autopct='%1.1f%%', colors = colors,\n",
    "        wedgeprops={'edgecolor': 'black', 'linewidth': 0.5},\n",
    "        startangle=90,\n",
    "        )\n",
    "ax1.set_title('Number of extinctions in 20 species data')\n",
    "\n",
    "# Second pie chart\n",
    "ax2.pie(pie_100, labels=pie_labels100, autopct='%1.1f%%', colors = colors,\n",
    "        wedgeprops={'edgecolor': 'black', 'linewidth': 0.5},\n",
    "        startangle=90,\n",
    "        )\n",
    "ax2.set_title('Number of extinctions in 100 species data')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/mnt/data/sur/users/mrivera/Plots/ext-pie.png', dpi = 300)  # Saves as PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a628c",
   "metadata": {},
   "source": [
    "We generate the distribution of extinctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea52b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of extinctions histogram\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Get log-counts with 20 species\n",
    "b1 = np.arange(0, 21, 1)\n",
    "ct1, _ = np.histogram(ext20, bins=21)\n",
    "ct1_log = np.log1p(ct1)  # log(count + 1) to avoid log(0)\n",
    "mask = ct1_log > 0\n",
    "\n",
    "# Get log-counts with 20 species\n",
    "b2 = np.arange(0, 101, 1)\n",
    "ct2, _ = np.histogram(ext20, bins=101)\n",
    "ct2_log = np.log1p(ct2)  # log(count + 1) to avoid log(0)\n",
    "\n",
    "# Create the plot\n",
    "plt.clf()  # Clear the entire figure\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot on first subplot\n",
    "ax1.plot(b1, ct1_log, marker='o', linestyle='-', color='blue')\n",
    "ax1.set_xlabel('Number of extinctions')\n",
    "ax1.set_ylabel('log(Frequency + 1)')\n",
    "ax1.set_title('Distribution with 20 species')\n",
    "ax1.set_xlim(0, 20)\n",
    "\n",
    "# Plot on first subplot\n",
    "ax2.plot(b2, ct2_log, marker='o', linestyle='-', color='red')\n",
    "ax2.set_xlabel('Number of extinctions')\n",
    "ax2.set_ylabel('log(Frequency + 1)')\n",
    "ax2.set_title('Distribution with 100 species')\n",
    "ax2.set_xlim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/mnt/data/sur/users/mrivera/Plots/exts-distr.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54f3e1e",
   "metadata": {},
   "source": [
    "# Correlation between variables\n",
    "\n",
    "## Run with 20 species\n",
    "* extinctions is correlated with bray_curtis with r=-0.02 for 20 species. Statistical significance: pval=8.17e-08\n",
    "\n",
    "* extinctions is correlated with keystone with r=-0.01 for 20 species. Statistical significance: pval=2.46e-07\n",
    "\n",
    "* extinctions is correlated with relative with r=-0.13 for 20 species. Statistical significance: pval=0.00e+00\n",
    "\n",
    "* bray_curtis is correlated with keystone with r=1.00 for 20 species. Statistical significance: pval=0.00e+00\n",
    "\n",
    "* bray_curtis is correlated with relative with r=0.08 for 20 species. Statistical significance: pval=6.66e-194\n",
    "\n",
    "* keystone is correlated with relative with r=0.08 for 20 species. Statistical significance: pval=1.28e-173\n",
    "\n",
    "## Run with 100 species\n",
    "* extinctions is correlated with bray_curtis with r=-0.02 for 100 species. Statistical significance: pval=8.17e-08\n",
    "\n",
    "* extinctions is correlated with keystone with r=-0.01 for 100 species. Statistical significance: pval=2.46e-07\n",
    "\n",
    "* extinctions is correlated with relative with r=-0.13 for 100 species. Statistical significance: pval=0.00e+00\n",
    "\n",
    "* bray_curtis is correlated with keystone with r=1.00 for 100 species. Statistical significance: pval=0.00e+00\n",
    "\n",
    "* bray_curtis is correlated with relative with r=0.08 for 100 species. Statistical significance: pval=6.66e-194\n",
    "\n",
    "* keystone is correlated with relative with r=0.08 for 100 species. Statistical significance: pval=1.28e-173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "# from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "import itertools\n",
    "\n",
    "def correlate(var1, var2, name1, name2, specs):\n",
    "    corr, pvalue = spearmanr(var1, var2)\n",
    "    print(f'>> {name1} is correlated with {name2} with r={corr:.2f} '\n",
    "          f'for {specs} species. Statistical significance: pval={pvalue:.2e}\\n')\n",
    "\n",
    "def run_correlation_suite(data, n_species):\n",
    "    keys = ['extinctions', 'bray_curtis', 'keystone', 'relative']\n",
    "    pairs = list(itertools.combinations(keys, 2))           # Generate combinations\n",
    "    for p in pairs:\n",
    "        name1, name2 = p[0], p[1]                           # Variable names\n",
    "        var1, var2 = data20[p[0]], data20[p[1]]             # Data\n",
    "        correlate(var1, var2, name1, name2, n_species)\n",
    "\n",
    "# Run correlation analyses\n",
    "run_correlation_suite(data20, 20)\n",
    "run_correlation_suite(data100, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52a0aa",
   "metadata": {},
   "source": [
    "## Plot correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093fae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c4bd62",
   "metadata": {},
   "source": [
    "# Distribution of keystoness and Bray-Curtis\n",
    "\n",
    "To determine the optimal number of bins, we can use the Freedman–Diaconis rule. However, since the interquartile range (IQR) is equal to zero in this case, the rule cannot be applied. Therefore, we use Scott’s rule as an alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7e66ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate optimal number of bins\n",
    "def bin_calc(x):\n",
    "    std = np.std(x)\n",
    "    n = len(x)\n",
    "    h_scott = 3.5 * std / (n ** (1/3))\n",
    "    bins_scott = int(np.ceil((x.max() - x.min()) / h_scott))\n",
    "    return bins_scott\n",
    "\n",
    "# Compute the number of bins\n",
    "x1 = np.round(Ks20, 5)\n",
    "bins1 = bin_calc(x1)\n",
    "x2 = np.round(Ks100, 5)\n",
    "bins2 = bin_calc(x2)\n",
    "\n",
    "# Generate the histogram for keystoness\n",
    "plt.clf()  # Clear the entire figure\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax1.hist(x1, bins=bins1, density=True, histtype='step',  color='blue', label='S20')  # 'step' draws only the outline\n",
    "ax1.hist(x2, bins=bins2, density=True, histtype='step', color='red', label='S100')  # 'step' draws only the outline\n",
    "ax1.set_xlabel('Keystoness')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Keystoness distribution')\n",
    "\n",
    "# Compute the number of bins\n",
    "x1 = np.round(Bc20, 5)\n",
    "x2 = np.round(Bc100, 5)\n",
    "bins1 = bin_calc(x1)\n",
    "bins2 = bin_calc(x2)\n",
    "ax2.hist(x1, bins=bins1, density=True, histtype='step',  color='blue', label='S20')  # 'step' draws only the outline\n",
    "ax2.hist(x2, bins=bins2, density=True, histtype='step', color='red', label='S100')  # 'step' draws only the outline\n",
    "ax2.set_xlabel('Bray-Curtis')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Bray-Curtis distribution')\n",
    "plt.legend()\n",
    "plt.savefig('/mnt/data/sur/users/mrivera/Plots/both-distr.png', dpi = 300)  # Saves as PNG\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a6bfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of bins using the  Freedman-Diaconis rule\n",
    "q75, q25 = np.percentile(Ks20, [75 ,25])            # quartile\n",
    "iqr = q75 - q25                                     # interquartile\n",
    "n = len(Ks20)\n",
    "h = 2 * iqr / (n ** (1/3))\n",
    "\n",
    "# Number of bins\n",
    "bins = int((Ks20.max() - Ks20.min()) / h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd90c14",
   "metadata": {},
   "source": [
    "# Kernel density estimation\n",
    "\n",
    "We will use Kernel Density Estimation (KDE) to estimate the probability density function of our data, based on the available observations."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
