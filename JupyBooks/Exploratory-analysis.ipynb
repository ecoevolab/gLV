{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eef6c753",
   "metadata": {},
   "source": [
    "## Exploratory data analysis\n",
    "\n",
    "This code performs an exploratory data analysis of the metrics calculated from the extinction events. The analyzed metrics include:\n",
    "\n",
    "* Number of new extinctions (new_ext)\n",
    "\n",
    "* Brayâ€“Curtis dissimilarity (BC_diss)\n",
    "\n",
    "* Keystoneness (K_s)\n",
    "\n",
    "* Time to stability after extinctions (ext_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Section: Generate-paths\n",
    "exp_dir = \"/mnt/data/sur/users/mrivera/Train-sims/4379fd40-9f0a\"\n",
    "tgt_dir = os.path.join(exp_dir, \"GNN-targets\")\n",
    "data_path = os.path.join(exp_dir, \"parameters-sims.tsv\")\n",
    "\n",
    "#  Load-data\n",
    "data = pd.read_csv(data_path, sep=\"\\t\")\n",
    "ids20 = data.loc[data['n_species'] == 20]['id']\n",
    "ids100 = data.loc[data['n_species'] == 100]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aadfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyarrow.feather as ft\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "TGT_DIR = '/mnt/data/sur/users/mrivera/Train-sims/4379fd40-9f0a/GNN-targets'  # Replace with actual path\n",
    "RAW_ODES_DIR = '/mnt/data/sur/users/mrivera/Train-sims/4379fd40-9f0a/raw-ODEs'\n",
    "\n",
    "def read_data(id):\n",
    "    # Load targets\n",
    "    x = ft.read_table(os.path.join(TGT_DIR, f'tgt_{id}.feather'))\n",
    "    ext = x['new_ext'].to_numpy()\n",
    "    Bc = np.round(x['BC_diss'].to_numpy(), 5)\n",
    "    Ks = np.round(x['K_s'].to_numpy(), 5)\n",
    "    # Load relative frequency\n",
    "    y = ft.read_table(os.path.join(RAW_ODES_DIR, f'O_{id}.feather'))\n",
    "    freq = y.column(-1).to_numpy()\n",
    "    # Calculate relative frequency \n",
    "    freq_sum = freq.sum()\n",
    "    rel = freq / freq_sum if freq_sum != 0 else np.zeros_like(freq)\n",
    "    return ext, Bc, Ks, rel\n",
    "\n",
    "\n",
    "def par_dat(ids, max_workers=8):\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(read_data, ids))\n",
    "    # Unpack and convert to numpy arrays\n",
    "    ext, Bc, Ks, rel= map(np.array, zip(*results))\n",
    "    # Flatten/concatenate the vectors\n",
    "    keys = ['extinctions', 'bray_curtis', 'keystone', 'relative']\n",
    "    data = {k: np.concatenate(v) for k, v in zip(keys, [ext, Bc, Ks, rel])}\n",
    "    return data\n",
    "     \n",
    "        \n",
    "# 20 (specs)* Number of simulations with 20 species\n",
    "data20 = par_dat(ids=ids20)\n",
    "data100 = par_dat(ids=ids100)\n",
    "\n",
    "# Test for lengths\n",
    "for key, value in data100.items():\n",
    "    print(f\"{key}: {len(value)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ac8814",
   "metadata": {},
   "source": [
    "# Relative frequencies distribution\n",
    "\n",
    "Generate a plot for relative frequencies distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f5b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# srun --partition=interactive --time=00:40:00 --cpus-per-task=8 --mem=20G --pty bash\n",
    "x1 = data20['relative']\n",
    "x2 = data100['relative']\n",
    "\n",
    "b1 = np.linspace(0, 1, 100)\n",
    "ct1, _ = np.histogram(x1, bins=100)\n",
    "ct2, _ = np.histogram(x2, bins=100)\n",
    "\n",
    "# Apply log\n",
    "ct1_log = np.log1p(ct1) \n",
    "ct2_log = np.log1p(ct2) \n",
    "\n",
    "# Plot distribution\n",
    "plt.clf()  # Clear the entire figure\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(b1, ct1_log, marker='o', linestyle='-', color='blue')\n",
    "plt.plot(b1, ct2_log, marker='o', linestyle='-', color='red')\n",
    "plt.xlabel('Relative frequencies')\n",
    "plt.ylabel('log(Frequency + 1)')\n",
    "plt.title('Distribution of relative frequencies')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/mnt/data/sur/users/mrivera/Plots/RelFreq-distr.png', dpi=300)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20db5beb",
   "metadata": {},
   "source": [
    "## Extinctions distribution\n",
    "We generate a function to compare the distribution of the number of extinctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e202bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate counting \n",
    "labels20, counts20 = np.unique(ext20, return_counts=True)\n",
    "labels100, counts100 = np.unique(ext100, return_counts=True)\n",
    "\n",
    "def pie_dat(labels, counts):\n",
    "    # Filter by >5% of data\n",
    "    rel = counts/sum(counts)\n",
    "    labels_final, counts_final, fail_counts = labels[rel > 0.05],  counts[rel > 0.05], counts[rel <= 0.05].sum()\n",
    "    # Pie chart final labels and counts\n",
    "    pie_labels= np.append(labels_final, 'other')\n",
    "    pie_counts= np.append(counts_final, fail_counts)\n",
    "    return pie_counts, pie_labels\n",
    "\n",
    "# Generate pie chart data\n",
    "pie_20, pie_labels20 = pie_dat(labels = labels20, counts = counts20)\n",
    "pie_100, pie_labels100 = pie_dat(labels = labels100, counts = counts100)\n",
    "\n",
    "# Generate the pie chart\n",
    "plt.clf()  # Clear the entire figure\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "colors = sns.color_palette('pastel')\n",
    "\n",
    "# First pie chart\n",
    "ax1.pie(pie_20, labels = pie_labels20, autopct='%1.1f%%', colors = colors,\n",
    "        wedgeprops={'edgecolor': 'black', 'linewidth': 0.5},\n",
    "        startangle=90,\n",
    "        )\n",
    "ax1.set_title('Number of extinctions in 20 species data')\n",
    "\n",
    "# Second pie chart\n",
    "ax2.pie(pie_100, labels=pie_labels100, autopct='%1.1f%%', colors = colors,\n",
    "        wedgeprops={'edgecolor': 'black', 'linewidth': 0.5},\n",
    "        startangle=90,\n",
    "        )\n",
    "ax2.set_title('Number of extinctions in 100 species data')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/mnt/data/sur/users/mrivera/Plots/ext-pie.png', dpi = 300)  # Saves as PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a628c",
   "metadata": {},
   "source": [
    "We generate the distribution of extinctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea52b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of extinctions histogram\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Get log-counts with 20 species\n",
    "b1 = np.arange(0, 21, 1)\n",
    "ct1, _ = np.histogram(ext20, bins=21)\n",
    "ct1_log = np.log1p(ct1)  # log(count + 1) to avoid log(0)\n",
    "mask = ct1_log > 0\n",
    "\n",
    "# Get log-counts with 20 species\n",
    "b2 = np.arange(0, 101, 1)\n",
    "ct2, _ = np.histogram(ext20, bins=101)\n",
    "ct2_log = np.log1p(ct2)  # log(count + 1) to avoid log(0)\n",
    "\n",
    "# Create the plot\n",
    "plt.clf()  # Clear the entire figure\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot on first subplot\n",
    "ax1.plot(b1, ct1_log, marker='o', linestyle='-', color='blue')\n",
    "ax1.set_xlabel('Number of extinctions')\n",
    "ax1.set_ylabel('log(Frequency + 1)')\n",
    "ax1.set_title('Distribution with 20 species')\n",
    "ax1.set_xlim(0, 20)\n",
    "\n",
    "# Plot on first subplot\n",
    "ax2.plot(b2, ct2_log, marker='o', linestyle='-', color='red')\n",
    "ax2.set_xlabel('Number of extinctions')\n",
    "ax2.set_ylabel('log(Frequency + 1)')\n",
    "ax2.set_title('Distribution with 100 species')\n",
    "ax2.set_xlim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/mnt/data/sur/users/mrivera/Plots/exts-distr.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54f3e1e",
   "metadata": {},
   "source": [
    "# Correlation between variables\n",
    "\n",
    "## Run with 20 species\n",
    "* extinctions is correlated with bray_curtis with r=-0.02 for 20 species. Statistical significance: pval=8.17e-08\n",
    "\n",
    "* extinctions is correlated with keystone with r=-0.01 for 20 species. Statistical significance: pval=2.46e-07\n",
    "\n",
    "* extinctions is correlated with relative with r=-0.13 for 20 species. Statistical significance: pval=0.00e+00\n",
    "\n",
    "* bray_curtis is correlated with keystone with r=1.00 for 20 species. Statistical significance: pval=0.00e+00\n",
    "\n",
    "* bray_curtis is correlated with relative with r=0.08 for 20 species. Statistical significance: pval=6.66e-194\n",
    "\n",
    "* keystone is correlated with relative with r=0.08 for 20 species. Statistical significance: pval=1.28e-173\n",
    "\n",
    "## Run with 100 species\n",
    "* extinctions is correlated with bray_curtis with r=-0.02 for 100 species. Statistical significance: pval=8.17e-08\n",
    "\n",
    "* extinctions is correlated with keystone with r=-0.01 for 100 species. Statistical significance: pval=2.46e-07\n",
    "\n",
    "* extinctions is correlated with relative with r=-0.13 for 100 species. Statistical significance: pval=0.00e+00\n",
    "\n",
    "* bray_curtis is correlated with keystone with r=1.00 for 100 species. Statistical significance: pval=0.00e+00\n",
    "\n",
    "* bray_curtis is correlated with relative with r=0.08 for 100 species. Statistical significance: pval=6.66e-194\n",
    "\n",
    "* keystone is correlated with relative with r=0.08 for 100 species. Statistical significance: pval=1.28e-173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "# from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "import itertools\n",
    "\n",
    "def correlate(var1, var2, name1, name2, specs):\n",
    "    corr, pvalue = spearmanr(var1, var2)\n",
    "    print(f'>> {name1} is correlated with {name2} with r={corr:.2f} '\n",
    "          f'for {specs} species. Statistical significance: pval={pvalue:.2e}\\n')\n",
    "\n",
    "def run_correlation_suite(data, n_species):\n",
    "    keys = ['extinctions', 'bray_curtis', 'keystone', 'relative']\n",
    "    pairs = list(itertools.combinations(keys, 2))           # Generate combinations\n",
    "    for p in pairs:\n",
    "        name1, name2 = p[0], p[1]                           # Variable names\n",
    "        var1, var2 = data20[p[0]], data20[p[1]]             # Data\n",
    "        correlate(var1, var2, name1, name2, n_species)\n",
    "\n",
    "# Run correlation analyses\n",
    "run_correlation_suite(data20, 20)\n",
    "run_correlation_suite(data100, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52a0aa",
   "metadata": {},
   "source": [
    "## Plot correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093fae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c4bd62",
   "metadata": {},
   "source": [
    "# Distribution of keystoness and Bray-Curtis\n",
    "\n",
    "To determine the optimal number of bins, we can use the Freedmanâ€“Diaconis rule. However, since the interquartile range (IQR) is equal to zero in this case, the rule cannot be applied. Therefore, we use Scottâ€™s rule as an alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7e66ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate optimal number of bins\n",
    "def bin_calc(x):\n",
    "    std = np.std(x)\n",
    "    n = len(x)\n",
    "    h_scott = 3.5 * std / (n ** (1/3))\n",
    "    bins_scott = int(np.ceil((x.max() - x.min()) / h_scott))\n",
    "    return bins_scott\n",
    "\n",
    "# Compute the number of bins\n",
    "x1 = np.round(Ks20, 5)\n",
    "bins1 = bin_calc(x1)\n",
    "x2 = np.round(Ks100, 5)\n",
    "bins2 = bin_calc(x2)\n",
    "\n",
    "# Generate the histogram for keystoness\n",
    "plt.clf()  # Clear the entire figure\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax1.hist(x1, bins=bins1, density=True, histtype='step',  color='blue', label='S20')  # 'step' draws only the outline\n",
    "ax1.hist(x2, bins=bins2, density=True, histtype='step', color='red', label='S100')  # 'step' draws only the outline\n",
    "ax1.set_xlabel('Keystoness')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Keystoness distribution')\n",
    "\n",
    "# Compute the number of bins\n",
    "x1 = np.round(Bc20, 5)\n",
    "x2 = np.round(Bc100, 5)\n",
    "bins1 = bin_calc(x1)\n",
    "bins2 = bin_calc(x2)\n",
    "ax2.hist(x1, bins=bins1, density=True, histtype='step',  color='blue', label='S20')  # 'step' draws only the outline\n",
    "ax2.hist(x2, bins=bins2, density=True, histtype='step', color='red', label='S100')  # 'step' draws only the outline\n",
    "ax2.set_xlabel('Bray-Curtis')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Bray-Curtis distribution')\n",
    "plt.legend()\n",
    "plt.savefig('/mnt/data/sur/users/mrivera/Plots/both-distr.png', dpi = 300)  # Saves as PNG\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a6bfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of bins using the  Freedman-Diaconis rule\n",
    "q75, q25 = np.percentile(Ks20, [75 ,25])            # quartile\n",
    "iqr = q75 - q25                                     # interquartile\n",
    "n = len(Ks20)\n",
    "h = 2 * iqr / (n ** (1/3))\n",
    "\n",
    "# Number of bins\n",
    "bins = int((Ks20.max() - Ks20.min()) / h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd90c14",
   "metadata": {},
   "source": [
    "# Kernel density estimation\n",
    "\n",
    "We will use Kernel Density Estimation (KDE) to estimate the probability density function of our data, based on the available observations."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
