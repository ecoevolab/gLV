{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eef6c753",
   "metadata": {},
   "source": [
    "## Exploratory data analysis\n",
    "\n",
    "This code performs an exploratory data analysis of the metrics calculated from the extinction events. The analyzed metrics include:\n",
    "\n",
    "* Number of new extinctions (new_ext)\n",
    "\n",
    "* Brayâ€“Curtis dissimilarity (BC_diss)\n",
    "\n",
    "* Keystoneness (K_s)\n",
    "\n",
    "* Time to stability after extinctions (ext_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "\n",
    "# Load data\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Section: Generate-paths\n",
    "exp_dir = \"/mnt/data/sur/users/mrivera/Train-sims/4379fd40-9f0a\"\n",
    "tgt_dir = os.path.join(exp_dir, \"GNN-targets\")\n",
    "data_path = os.path.join(exp_dir, \"parameters-sims.tsv\")\n",
    "\n",
    "#  Load-data\n",
    "data = pd.read_csv(data_path, sep=\"\\t\")\n",
    "ids20 = data.loc[data['n_species'] == 20]['id']\n",
    "ids100 = data.loc[data['n_species'] == 100]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aadfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# | eval: false\n",
    "\n",
    "import pyarrow.feather as ft\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "TGT_DIR = '/mnt/data/sur/users/mrivera/Train-sims/4379fd40-9f0a/GNN-targets'  # Replace with actual path\n",
    "RAW_ODES_DIR = '/mnt/data/sur/users/mrivera/Train-sims/4379fd40-9f0a/raw-ODEs'\n",
    "\n",
    "def read_data(id):\n",
    "    # Load targets - read only needed columns\n",
    "    x = ft.read_table(\n",
    "        os.path.join(TGT_DIR, f'tgt_{id}.feather'),\n",
    "        columns=['new_ext', 'BC_diss', 'K_s']\n",
    "    )\n",
    "    # Convert to numpy - PyArrow arrays are read-only, so copy for rounding\n",
    "    ext = x['new_ext'].to_numpy()\n",
    "    Bc = np.round(x['BC_diss'].to_numpy(), 5)\n",
    "    Ks = np.round(x['K_s'].to_numpy(), 5)\n",
    "    # Load relative frequency - read only last column\n",
    "    y = ft.read_table(os.path.join(RAW_ODES_DIR, f'O_{id}.feather'))\n",
    "    freq = y.column(-1).to_numpy()\n",
    "    # Vectorized relative frequency calculation\n",
    "    freq_sum = freq.sum()\n",
    "    rel = freq / freq_sum if freq_sum != 0 else freq * 0  # Faster than zeros_like\n",
    "    return ext, Bc, Ks, rel\n",
    "\n",
    "\n",
    "\n",
    "def par_dat_preallocate(ids, max_workers=None):\n",
    "    # Detect number of cores\n",
    "    if max_workers is None:\n",
    "        max_workers = len(os.sched_getaffinity(0))\n",
    "    # 4 batches per worker\n",
    "    chunksize = max(1, len(ids) // (max_workers * 4))\n",
    "    # Parallelize function\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(read_data, ids, chunksize=chunksize))\n",
    "    # Calculate total sizes\n",
    "    size_ext = sum(len(r[0]) for r in results)\n",
    "    size_Bc = sum(len(r[1]) for r in results)\n",
    "    size_Ks = sum(len(r[2]) for r in results)\n",
    "    size_rel = sum(len(r[3]) for r in results)\n",
    "    # Pre-allocate output arrays\n",
    "    ext_all = np.empty(size_ext, dtype=results[0][0].dtype)\n",
    "    Bc_all = np.empty(size_Bc, dtype=results[0][1].dtype)\n",
    "    Ks_all = np.empty(size_Ks, dtype=results[0][2].dtype)\n",
    "    rel_all = np.empty(size_rel, dtype=results[0][3].dtype)\n",
    "    # Fill arrays efficiently\n",
    "    pos_ext = pos_Bc = pos_Ks = pos_rel = 0\n",
    "    for ext, Bc, Ks, rel in results:\n",
    "        n_ext, n_Bc, n_Ks, n_rel = len(ext), len(Bc), len(Ks), len(rel)\n",
    "        ext_all[pos_ext:pos_ext+n_ext] = ext\n",
    "        Bc_all[pos_Bc:pos_Bc+n_Bc] = Bc\n",
    "        Ks_all[pos_Ks:pos_Ks+n_Ks] = Ks\n",
    "        rel_all[pos_rel:pos_rel+n_rel] = rel\n",
    "        pos_ext += n_ext\n",
    "        pos_Bc += n_Bc\n",
    "        pos_Ks += n_Ks\n",
    "        pos_rel += n_rel\n",
    "    return {\n",
    "        'extinctions': ext_all,\n",
    "        'bray_curtis': Bc_all,\n",
    "        'keystone': Ks_all,\n",
    "        'relative': rel_all\n",
    "    }\n",
    "\n",
    "        \n",
    "# 20 (specs)* Number of simulations with 20 species\n",
    "data20 = par_dat_preallocate(ids=ids20)\n",
    "data100 = par_dat_preallocate(ids=ids100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ac8814",
   "metadata": {},
   "source": [
    "# Relative frequencies distribution\n",
    "\n",
    "Generate a plot for relative frequencies distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f5b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# srun --partition=interactive --time=00:40:00 --cpus-per-task=8 --mem=20G --pty bash\n",
    "b1 = np.linspace(0, 1, 100)\n",
    "ct1, _ = np.histogram(data20['relative'], bins=100)\n",
    "ct2, _ = np.histogram(data100['relative'], bins=100)\n",
    "\n",
    "# Apply log\n",
    "ct20_log = np.log1p(ct1) \n",
    "ct100_log = np.log1p(ct2) \n",
    "\n",
    "# Plot distribution\n",
    "plt.clf()  # Clear the entire figure\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(b1, ct20_log, marker='o', linestyle='-', color='blue', label='20 species')\n",
    "plt.plot(b1, ct100_log, marker='o', linestyle='-', color='red', label='100 species')\n",
    "plt.xlabel('Relative frequencies')\n",
    "plt.ylabel('log(Frequency + 1)')\n",
    "plt.title('Distribution of relative frequencies')\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('/mnt/data/sur/users/mrivera/Plots/RelFreq-distr.png', dpi=300)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f9280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "img = mpimg.imread('/mnt/data/sur/users/mrivera/Plots/RelFreq-distr.png')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20db5beb",
   "metadata": {},
   "source": [
    "## Extinctions distribution\n",
    "We generate a function to compare the distribution of the number of extinctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e202bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate counting \n",
    "labels20, counts20 = np.unique(data20['extinctions'], return_counts=True)\n",
    "labels100, counts100 = np.unique(data100['extinctions'], return_counts=True)\n",
    "\n",
    "def pie_dat(labels, counts):\n",
    "    # Filter by >5% of data\n",
    "    rel = counts/sum(counts)\n",
    "    labels_final, counts_final, fail_counts = labels[rel > 0.05],  counts[rel > 0.05], counts[rel <= 0.05].sum()\n",
    "    # Pie chart final labels and counts\n",
    "    pie_labels= np.append(labels_final, 'other')\n",
    "    pie_counts= np.append(counts_final, fail_counts)\n",
    "    return pie_counts, pie_labels\n",
    "\n",
    "# Generate pie chart data\n",
    "pie_20, pie_labels20 = pie_dat(labels = labels20, counts = counts20)\n",
    "pie_100, pie_labels100 = pie_dat(labels = labels100, counts = counts100)\n",
    "\n",
    "# Generate the pie chart\n",
    "plt.clf()  # Clear the entire figure\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "colors = sns.color_palette('pastel')\n",
    "\n",
    "# First pie chart 20 species\n",
    "ax1.pie(pie_20, labels=pie_labels20, autopct='%1.1f%%', colors=colors,\n",
    "        wedgeprops={'edgecolor': 'white', 'linewidth': 2},\n",
    "        startangle=90,\n",
    "        textprops={'fontsize': 11, 'weight': 'bold'},\n",
    "        pctdistance=0.85,\n",
    "        explode=[0.05] * len(pie_20)  # Slightly separate all slices\n",
    "        )\n",
    "ax1.set_title('Number of extinctions in 20 species data', fontweight='bold')\n",
    "\n",
    "# Second pie chart 100 species\n",
    "ax2.pie(pie_100, labels=pie_labels100, autopct='%1.1f%%', colors=colors,\n",
    "        wedgeprops={'edgecolor': 'white', 'linewidth': 2},\n",
    "        startangle=90,\n",
    "        textprops={'fontsize': 11, 'weight': 'bold'},\n",
    "        pctdistance=0.85,\n",
    "        explode=[0.05] * len(pie_100)  # Slightly separate all slices\n",
    "        )\n",
    "ax2.set_title('Number of extinctions in 100 species data', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/mnt/data/sur/users/mrivera/Plots/ext-pie.png', dpi = 300)  # Saves as PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "img = mpimg.imread('/mnt/data/sur/users/mrivera/Plots/ext-pie.png')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1519f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the fugure\n",
    "plt.clf()  # Clear the entire figure\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "colors = sns.color_palette('pastel')\n",
    "\n",
    "# Get histogram data\n",
    "counts, bins, patches = np.histogram(data20['extinctions'], bins=20)\n",
    "counts_log = np.log1p(counts)  # log(x+1)\n",
    "ax1.bar(bins[:-1], counts_log, width=np.diff(bins), edgecolor='black', \n",
    "        color = colors[0], linewidth=1.5, align='edge')\n",
    "ax1.set_xlabel('Number of extinctions', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('log(Frequency + 1)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Extinctions with 20 species', fontsize=14, fontweight='bold', pad=15)  # Fixed title\n",
    "ax1.set_xlim(0, 20)  # Set x-axis limit to 20\n",
    "\n",
    "# Get histogram data\n",
    "counts, bins, patches = np.histogram(data100['extinctions'], bins=100)\n",
    "counts_log = np.log1p(counts)  # log(x+1)\n",
    "ax2.bar(bins[:-1], counts_log, width=np.diff(bins), edgecolor='black', \n",
    "        color = colors[1], linewidth=1.5, align='edge')\n",
    "ax2.set_xlabel('Number of extinctions', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('log(Frequency + 1)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Extinctions with 100 species', fontsize=14, fontweight='bold', pad=15)  # Fixed title\n",
    "ax2.set_xlim(0, 100)  # Set x-axis limit to 100\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/mnt/data/sur/users/mrivera/Plots/ext-histogram.png', dpi = 300)  # Saves as PNG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6af0bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "img = mpimg.imread('/mnt/data/sur/users/mrivera/Plots/ext-histogram.png')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a628c",
   "metadata": {},
   "source": [
    "## HeatMap of relative frequency vs number of extinctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea52b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "\n",
    "# Distribution of extinctions histogram\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create figure with two subplots\n",
    "plt.clf()  # Clear the entire figure\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Compute 2D histogram\n",
    "H, xedges, yedges = np.histogram2d(\n",
    "    data20['relative'], \n",
    "    data20['extinctions'], \n",
    "    bins=[10, 10]\n",
    ")\n",
    "\n",
    "# Apply log transformation to counts (add 1 to avoid log(0))\n",
    "H_log = np.log1p(H.T)  \n",
    "H_log_masked = np.ma.masked_where(H_log == 0, H_log)\n",
    "\n",
    "# Create the heatmap on ax1\n",
    "im1 = ax1.imshow(\n",
    "    H_log, # Transpose to match plot orientation\n",
    "    origin='lower',\n",
    "    aspect='auto',\n",
    "    extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]],\n",
    "    cmap='coolwarm',\n",
    "    interpolation='nearest'\n",
    ")\n",
    "\n",
    "fig.colorbar(im1, ax=ax1, label='Log(Frequency)')\n",
    "ax1.set_xlabel('Relative Frequency')\n",
    "ax1.set_ylabel('Number of Extinctions')\n",
    "ax1.set_title('20 Species')\n",
    "\n",
    "# For 100 species (ax2)\n",
    "H100, xedges100, yedges100 = np.histogram2d(\n",
    "    data100['relative'], \n",
    "    data100['extinctions'], \n",
    "    bins=[10, 10]\n",
    ")\n",
    "H100_log = np.log1p(H100.T)\n",
    "\n",
    "im2 = ax2.imshow(\n",
    "    H100_log, \n",
    "    origin='lower',\n",
    "    aspect='auto',\n",
    "    extent=[xedges100[0], xedges100[-1], yedges100[0], yedges100[-1]],\n",
    "    cmap='coolwarm',\n",
    "    interpolation='nearest'\n",
    ")\n",
    "\n",
    "fig.colorbar(im2, ax=ax2, label='Log(Frequency)')\n",
    "ax2.set_xlabel('Relative Frequency')\n",
    "ax2.set_ylabel('Number of Extinctions')\n",
    "ax2.set_title('100 Species')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/mnt/data/sur/users/mrivera/Plots/exts-distr.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138ee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "img = mpimg.imread('/mnt/data/sur/users/mrivera/Plots/exts-distr.png')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54f3e1e",
   "metadata": {},
   "source": [
    "# Correlation between variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d79d39f",
   "metadata": {},
   "source": [
    "### Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# | eval: false\n",
    "\n",
    "import numpy as np \n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "import itertools\n",
    "\n",
    "def pearson_cor(var1, var2, name1, name2, specs):\n",
    "    corr, pvalue = pearsonr(var1, var2)\n",
    "    return f'>> Pearson correlation of {name1} with {name2}, is correlated with r={corr:.6f} for {specs} species. Statistical significance: pval={pvalue:.2e}\\n'\n",
    "    \n",
    "\n",
    "def spearman_cor(var1, var2, name1, name2, specs):\n",
    "    corr, pvalue = spearmanr(var1, var2)\n",
    "    return f'>> Spearman correlation of {name1} with {name2}, is correlated with r={corr:.6f} for {specs} species. Statistical significance: pval={pvalue:.2e}\\n'\n",
    "\n",
    "\n",
    "def run_correlation(data, n_species):\n",
    "    # Create list for lines\n",
    "    lines_pearson = []\n",
    "    lines_spearman = []\n",
    "    # Generate combinations\n",
    "    keys = ['extinctions', 'bray_curtis', 'keystone', 'relative']\n",
    "    pairs = list(itertools.combinations(keys, 2))           \n",
    "    for p in pairs:\n",
    "        name1, name2 = p[0], p[1]                           # Variable names\n",
    "        var1, var2 = data[p[0]], data[p[1]]             # Data\n",
    "        lines_pearson.append( pearson_cor(var1, var2, name1, name2, n_species) )\n",
    "        lines_spearman.append( spearman_cor(var1, var2, name1, name2, n_species) )\n",
    "    # Write files\n",
    "    with open(f'/mnt/data/sur/users/mrivera/Logs/pearson{n_species}_correlation.txt', 'w') as f:\n",
    "        f.writelines(lines_pearson)\n",
    "    with open(f'/mnt/data/sur/users/mrivera/Logs/spearman{n_species}_correlation.txt', 'w') as f:\n",
    "        f.writelines(lines_spearman)\n",
    "\n",
    "\n",
    "# Run it\n",
    "run_correlation(data20, 20)\n",
    "run_correlation(data100, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0956ca8f",
   "metadata": {},
   "source": [
    "## Run with 20 species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c697cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/data/sur/users/mrivera/Logs/pearson20_correlation.txt', 'r') as f:\n",
    "    content = f.read()\n",
    "    print(content)\n",
    "\n",
    "with open('/mnt/data/sur/users/mrivera/Logs/spearman20_correlation.txt', 'r') as f:\n",
    "    content = f.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6218214",
   "metadata": {},
   "source": [
    "## Run with 100 species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746ba3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/data/sur/users/mrivera/Logs/pearson100_correlation.txt', 'r') as f:\n",
    "    content = f.read()\n",
    "    print(content)\n",
    "\n",
    "with open('/mnt/data/sur/users/mrivera/Logs/spearman100_correlation.txt', 'r') as f:\n",
    "    content = f.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52a0aa",
   "metadata": {},
   "source": [
    "## Plot correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093fae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Convert to pandas DataFrame if it's not already\n",
    "data20_df = pd.DataFrame(data20)\n",
    "cols = ['extinctions', 'bray_curtis', 'keystone', 'relative']\n",
    "\n",
    "# Create pairplot with only lower triangle\n",
    "plt.clf()  # Clear the entire figure\n",
    "pairplot = sns.pairplot(data20_df[['extinctions', 'bray_curtis', 'keystone', 'relative']], corner=True)\n",
    "\n",
    "# Loop through the diagonal axes and set y labels\n",
    "for ax in pairplot.axes[:, 0]:  # leftmost column\n",
    "    if ax is not None:\n",
    "        ax.set_ylabel(ax.get_ylabel(), rotation=0, labelpad=40, fontsize=10)\n",
    "\n",
    "pairplot.fig.suptitle('Pairplot for 20 Species', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "plt.tight_layout()\n",
    "pairplot.savefig('/mnt/data/sur/users/mrivera/Plots/pairplot_python.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb4a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "img = mpimg.imread('/mnt/data/sur/users/mrivera/Plots/pairplot.png')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
