{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ff921d0",
   "metadata": {},
   "source": [
    "This file was created for running pytorch learning at cluster without GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a6620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION: Define-GNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "class simple_gnn_gcn(nn.Module):\n",
    "    def __init__(self,  hidden_channels=64):\n",
    "        super().__init__()\n",
    "        self.conv1 = GraphConv(1, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, 1)\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_weights\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = torch.sigmoid(x)  # Outputs between 0-1\n",
    "        return x  # [num_nodes]\n",
    "    \n",
    "\n",
    "\n",
    "model = simple_gnn_gcn(hidden_channels=72).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "loss_fn = nn.MSELoss()                                                # Loss function for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01) \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8429030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import DataLoader\n",
    "import time\n",
    "\n",
    "# Declare data paths\n",
    "directory = '/mnt/data/sur/users/mrivera/Train-sims/4379fd40-9f0a/batching'\n",
    "train_files = glob.glob(f'{directory}/TrainBatch_*.pt')\n",
    "\n",
    "# Testing lines\n",
    "path = train_files[1]\n",
    "loader = DataLoader(data, batch_size=32, shuffle=False)\n",
    "\n",
    "epochs = 10\n",
    "model.train()\n",
    "# Empty lists for predictions, targets, loss at each epoch\n",
    "x_train, y_train, loss_epochs  = [], [], []\n",
    "total_elapsed = 0\n",
    "for iter in range(1, epochs+1):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    for path in dat_batched:\n",
    "        data = torch.load(path, weights_only=False)           \n",
    "        loader = DataLoader(data, batch_size=200, shuffle=True)\n",
    "        for batch in loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch)\n",
    "            loss = loss_fn(out, batch.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()   # Accumulate loss\n",
    "            # print(data)\n",
    "            if iter == epochs:\n",
    "                x_train.append(out.cpu().detach().numpy()) \n",
    "                y_train.append(batch.y.cpu().detach().numpy())\n",
    "    loss_epochs.append(round(total_loss))\n",
    "    elapsed = time.time() - start\n",
    "    total_elapsed += elapsed\n",
    "    print(f\"Epoch {iter}: Loss = {total_loss:.4f},  Elapsed time: {elapsed:.2f}\")\n",
    "    \n",
    "\n",
    "print(f'>> the total elapsed time with {epochs} epochs is {total_elapsed/60:.2f} minutes')      \n",
    "\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5aaeda",
   "metadata": {},
   "source": [
    "## Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def loss_plotter(loss_epochs = None, epochs = None):\n",
    "    # After collecting your data\n",
    "    y = np.round(loss_epochs, 3)\n",
    "    x = list(range(0, epochs))\n",
    "    # Create scatter plot\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.plot(x, y, alpha=0.5)\n",
    "    # Add perfect prediction line (y=x)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    ymin = min(y) \n",
    "    plt.ylim(ymin, max(y))\n",
    "    plt.xlim(0, max(x))\n",
    "    return fig\n",
    "\n",
    "fig = loss_plotter(loss_epochs, epochs)\n",
    "fig.savefig('/mnt/data/sur/users/mrivera/Plots/4379fd40-9f0a-loss.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c434816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_plotter(preds = None, tgts = None, path = None ):\n",
    "    # After collecting your data\n",
    "    preds = np.concatenate(preds)  # predictions\n",
    "    tgts = np.concatenate(tgts)  # targets\n",
    "    # Create scatter plot\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(preds, tgts, alpha=0.5)\n",
    "   # Add perfect prediction line (y=x)\n",
    "    plt.plot([0,  np.max(tgts)], [0,  np.max(tgts)], 'r--', label='Perfect prediction')\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('True Values')\n",
    "    plt.title('Predictions vs True Values')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(0, max(tgts))\n",
    "    plt.xlim(0, max(tgts))\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
