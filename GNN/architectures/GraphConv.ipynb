{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ff921d0",
   "metadata": {},
   "source": [
    "This file was created for running pytorch learning with CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a6620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION: Define-GNN\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class simple_gnn_gcn(nn.Module):\n",
    "    def __init__(self,  hidden_channels=64):\n",
    "        super().__init__()\n",
    "        self.conv1 = GraphConv(1, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, 1)\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_weights\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = torch.sigmoid(x)  # Outputs between 0-1\n",
    "        return x  # [num_nodes]\n",
    "\n",
    "def seed_fn(seed=42):\n",
    "    # Set ALL seeds for full reproducibility\n",
    "    torch.manual_seed(seed)                 # Seed CPU \n",
    "    torch.cuda.manual_seed(seed)            # Seed GPU\n",
    "    np.random.seed(seed)                    # Seed numpy\n",
    "    random.seed(seed)                       # Seed python random\n",
    "    torch.backends.cudnn.deterministic = True   # Ensure deterministic behavior\n",
    "    torch.backends.cudnn.benchmark = False \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea57d6",
   "metadata": {},
   "source": [
    "# Training mode\n",
    "\n",
    "For training the model we use the next function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8429030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import DataLoader\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch \n",
    "\n",
    "# Declare data paths\n",
    "directory = '/home/mriveraceron/data/exp_20251125'\n",
    "train_files = glob.glob(f'{directory}/TrainBatch_*.pt')\n",
    "\n",
    "\n",
    "# Testing lines\n",
    "path = train_files[1]\n",
    "data = torch.load(path, weights_only=False) \n",
    "loader = DataLoader(data, batch_size=32, shuffle=False)\n",
    "\n",
    "def training_loop(model, dat_batched, loss_fn, optimizer, epochs=100):\n",
    "    model.train()\n",
    "    # Empty lists for predictions, targets, loss at each epoch\n",
    "    x_train, y_train, loss_epochs  = [], [], []\n",
    "    total_elapsed = 0\n",
    "    for iter in range(1, epochs+1):\n",
    "        start = time.time()\n",
    "        total_loss = 0\n",
    "        for path in dat_batched:\n",
    "            data = torch.load(path, weights_only=False)          \n",
    "            loader = DataLoader(data, batch_size=50, shuffle=True)\n",
    "            for batch in loader:\n",
    "                batch = batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = model(batch)\n",
    "                loss = loss_fn(out, batch.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()   # Accumulate loss\n",
    "                # print(data)\n",
    "                if iter == epochs:\n",
    "                    x_train.append(out.cpu().detach().numpy()) \n",
    "                    y_train.append(batch.y.cpu().detach().numpy())\n",
    "        loss_epochs.append(total_loss)\n",
    "        elapsed = time.time() - start\n",
    "        total_elapsed += elapsed\n",
    "        print(f\"Epoch {iter}: Loss = {total_loss:.4f},  Elapsed time: {elapsed:.2f}\")\n",
    "    print(f'>> the total elapsed time with {epochs} epochs is {total_elapsed:.2f} seconds ( {total_elapsed/60:.2f} minutes)')\n",
    "    # Concatenate all predictions\n",
    "    x_train = np.concatenate(x_train, axis=0)\n",
    "    y_train = np.concatenate(y_train, axis=0)      \n",
    "    return x_train, y_train, loss_epochs\n",
    "\n",
    "\n",
    "# Run training loop.\n",
    "seed_fn(38)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = simple_gnn_gcn(hidden_channels=60).to(device)\n",
    "loss_fn = nn.MSELoss()                                                # Loss function for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01) \n",
    "xtr, ytr, loss_train = training_loop(model, train_files, loss_fn, optimizer, epochs=1000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819c9b83",
   "metadata": {},
   "source": [
    "## Plot loss over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ea5745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b1e3752",
   "metadata": {},
   "source": [
    "# Validation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3719494d",
   "metadata": {},
   "source": [
    "## Maximum keystoness for each community vs prediction\n",
    "\n",
    "This validation process evaluates the performance of a previously trained model by measuring its ability to predict maximum y values across different communities. The validation metric is expressed as a percentage accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2336e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validation files\n",
    "valid_files = glob.glob(f'{directory}/ValBatch_*.pt')\n",
    "\n",
    "def validation_fn(model, files, loss_fn, device):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    total_loss = 0\n",
    "    true_max, predicted_max = [], []\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for path in files:\n",
    "            data_list = torch.load(path, weights_only=False)                            # Load data\n",
    "            true_max.extend( [round(data.y.max().item(), 5) for data in data_list] )    # True max per sample\n",
    "            loader = DataLoader(data_list, batch_size=50, shuffle=False)                # Batch data   \n",
    "            for batch in loader:\n",
    "                data = batch.to(device)\n",
    "                # Forward pass only\n",
    "                out = model(data)\n",
    "                loss = loss_fn(out, data.y)\n",
    "                total_loss += loss.item()\n",
    "                max_values = out.max(dim=1)[0].detach().cpu().tolist()   # Predicted max per sample\n",
    "                predicted_max.extend([round(x, 5) for x in max_values])\n",
    "                print(f\"Graphs per batch: {batch.num_graphs}\")\n",
    "                print(f\"Total nodes in batch: {batch.num_nodes}\")   # x are the nodes\n",
    "                print(f\"x (nodes) shape: {batch.x.shape}\")\n",
    "                print(f\"y shape: {batch.y.shape}\")\n",
    "                print(f\"batch vector: {batch.batch}\")\n",
    "                print(f'Shape of max outs {out.max(dim=1)[0].shape}')\n",
    "                print(\"---\")\n",
    "    return true_max, predicted_max, total_loss\n",
    "\n",
    "# How zip works\n",
    "# a = [0.5, 0.80, 1.20]\n",
    "# b = [0, 0.60, 0.80]\n",
    "# x = [a - b for a, b in zip(a, b)]\n",
    "\n",
    "true_max, predicted_max, total_loss = validation_fn(model, valid_files, loss_fn, device)\n",
    "diff = [a - b for a, b in zip(true_max, predicted_max)]\n",
    " \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e96530",
   "metadata": {},
   "source": [
    "# Some other code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d2cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_files = glob.glob(f'{directory}/ValBatch_*.pt')\n",
    "\n",
    "# Get maximum y values (keystone) for each community\n",
    "max_y_values = []\n",
    "for path in valid_files:\n",
    "    # Load data from file\n",
    "    data_list = torch.load(path, weights_only=False)\n",
    "    # Get max y value for each community\n",
    "    max_y_values.append( [round(data.y.max().item(), 5) for data in data_list] )\n",
    "# Flatten list\n",
    "max_y_flatten = [item for sublist in max_y_values for item in sublist]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e76182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_files = glob.glob(f'{directory}/ValBatch_*.pt')\n",
    "\n",
    "def validation_fn(model, files, loss_fn, device):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    total_loss = 0\n",
    "    predicted_values, true_values, true_max, preds_max = [], [], [], []\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for path in files:\n",
    "            data_list = torch.load(path, weights_only=False)\n",
    "            true_values.append( [round(data.y.max().item(), 5) for data in data_list] )\n",
    "            loader = DataLoader(data, batch_size=50, shuffle=False)  \n",
    "            for batch in loader:\n",
    "                batch = batch.to(device)\n",
    "                # Forward pass only\n",
    "                out = model(data)\n",
    "                loss = loss_fn(out, data.y)\n",
    "                total_loss += loss.item()\n",
    "                # Get max predictions per sample\n",
    "                tmp = out.max(dim=1)[0] \n",
    "                preds_max.append(tmp.cpu().detach().numpy())\n",
    "                predicted_values.append(out.cpu().detach().numpy())    # Predictions\n",
    "                true_values.append(batch.y.cpu().detach().numpy())     # Taregts\n",
    "                print(f\"Batch size: {batch.num_graphs}\")  # For PyG Data objects\n",
    "                print(f\"Output shape: {out.shape}\")\n",
    "                print(f\"Output values:\\n{out}\")\n",
    "                print(f\"Max preds shape: {preds_max.shape}\")\n",
    "                print(f\"Max preds values: {preds_max}\")\n",
    "        # Concatenate all predictions\n",
    "        true_max = np.concatenate(true_max, axis=0)\n",
    "        preds_max = np.concatenate(preds_max, axis=0)\n",
    "        predicted_values = np.concatenate(predicted_values, axis=0)\n",
    "        true_values = np.concatenate(true_values, axis=0)\n",
    "    return true_max, preds_max, predicted_values, true_values, loss\n",
    "\n",
    "x_val, y_val, loss_val = validation_fn(model, valid_files, loss_fn, device)\n",
    "\n",
    "# Testing lines\n",
    "for path in valid_files:\n",
    "    total_loss = 0\n",
    "    predicted_values, true_values, true_max, preds_max = [], [], [], []\n",
    "    path = valid_files[0]\n",
    "    data_list = torch.load(path, weights_only=False)\n",
    "    # Get max y value for each community\n",
    "    values = [round(data.y.max().item(), 4) for data in data_list]\n",
    "    true_max.extend ( values )\n",
    "    print(f'The true max values are: {len(values)}')\n",
    "    # Batch data\n",
    "    loader = DataLoader(data, batch_size=50, shuffle=False) \n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        # Forward pass only\n",
    "        out = model(batch)\n",
    "        loss = loss_fn(out, batch.y)\n",
    "        total_loss += loss.item()\n",
    "        # Get max predictions per sample\n",
    "        tmp = out.max(dim=1)[0] \n",
    "        # Get predictions and targets\n",
    "        for i in range(batch.num_graphs):\n",
    "            # Load individual graph\n",
    "            start_idx = batch.ptr[i]\n",
    "            end_idx = batch.ptr[i + 1]\n",
    "            # Get predictions for this graph and find max\n",
    "            graph_preds = out[start_idx:end_idx]\n",
    "            # print(f'This is a testing, the number of features is: {len(out[start_idx:end_idx])}')\n",
    "            max_pred = round(graph_preds.max().item(), 4)\n",
    "            preds_max.append(max_pred)\n",
    "        print(f'The number of graphs in the batch is: {batch.num_graphs}')\n",
    "        print(f\"Output shape: {out.shape}\")\n",
    "        print(f\"tmp shape: {tmp.shape}\")\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "    print(i)\n",
    "\n",
    "loader = DataLoader(data, batch_size=50, shuffle=False)  \n",
    "for batch in loader:\n",
    "    batch = batch.to(device)\n",
    "    # Forward pass only\n",
    "    out = model(data)\n",
    "    loss = loss_fn(out, data.y)\n",
    "    total_loss += loss.item()\n",
    "    # Get max predictions per sample\n",
    "    tmp = out.max(dim=1)[0] \n",
    "    preds_max.append(tmp.cpu().detach().numpy())\n",
    "    predicted_values.append(out.cpu().detach().numpy())    # Predictions\n",
    "    true_values.append(batch.y.cpu().detach().numpy())     # Taregts\n",
    "    print(f\"Batch size: {batch.num_graphs}\")  # For PyG Data objects\n",
    "    print(f\"Output shape: {out.shape}\")\n",
    "    print(f\"Output values:\\n{out}\")\n",
    "    print(f\"Max preds shape: {preds_max.shape}\")\n",
    "    print(f\"Max preds values: {preds_max}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2b8ce",
   "metadata": {},
   "source": [
    "# Understanding pytorch Dataloader\n",
    "\n",
    "\n",
    "The following code demonstrates how to get the maximum value of the y tensor for each individual sample (graph) when using DataLoader for batching in PyTorch Geometric.\n",
    "\n",
    "## Problem\n",
    "When graphs are batched together using DataLoader, all node features and labels are concatenated. The `batch` vector indicates which nodes belong to which graph, but we need to extract the maximum y value for each original graph separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "from torch_geometric.nn import global_max_pool\n",
    "\n",
    "# Original Data objects:\n",
    "dataset = []\n",
    "for i in range(5):\n",
    "    data = Data(x=torch.randn(10, 1), y=torch.tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, (i+1)*(10**(i+1))]))\n",
    "    dataset.append(data)\n",
    "\n",
    "# Create DataLoader\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# How batches work\n",
    "batch = Batch.from_data_list(dataset)                   # Create batch\n",
    "print(f\"batch.batch: {batch.batch}\")                    # To which graph each node belongs \n",
    "print(f\"batch.y: {batch.y}\")                            # All y values concatenated\n",
    "print(f\"Total nodes: {batch.num_nodes}\")                # Number of nodes in the batch\n",
    "print(f\"Number of graphs: {batch.num_graphs}\")          # Number of graphs in the batch\n",
    "\n",
    "# Iterate through batches\n",
    "vector = []\n",
    "for batch in loader:\n",
    "    print(f\"Graphs per batch: {batch.num_graphs}\")\n",
    "    print(f\"Total nodes in batch: {batch.num_nodes}\")   # x are the nodes\n",
    "    print(f\"x (nodes) shape: {batch.x.shape}\")\n",
    "    print(f\"y shape: {batch.y.shape}\")\n",
    "    print(f\"batch vector: {batch.batch}\")\n",
    "    # print(f'testing: {batch.y.unsqueeze(-1)}')\n",
    "    max_y_per_graph = global_max_pool(batch.y.unsqueeze(-1), batch.batch).squeeze(-1)\n",
    "    vector.extend( max_y_per_graph.tolist() )\n",
    "    print(f\"Max y per graph: {max_y_per_graph}\")\n",
    "    print(\"---\")\n",
    "\n",
    "sorted(vector)\n",
    "\n",
    "# How does unsqueeze work?\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "x.size()\n",
    "torch.unsqueeze(x, -1).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8b881b",
   "metadata": {},
   "source": [
    "# Multiple seeds testing\n",
    "\n",
    "As initial weight matrix is completely random, testing for multiple seeds and the choosing of the best one has to be tested. For this purpose we generate some seeds and test for improvement in loss over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad14c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def seed_fn(seed=42):\n",
    "    # Set ALL seeds for full reproducibility\n",
    "    torch.manual_seed(seed)                 # Seed CPU \n",
    "    torch.cuda.manual_seed(seed)            # Seed GPU\n",
    "    np.random.seed(seed)                    # Seed numpy\n",
    "    random.seed(seed)                       # Seed python random\n",
    "    torch.backends.cudnn.deterministic = True   # Ensure deterministic behavior\n",
    "    torch.backends.cudnn.benchmark = False \n",
    "\n",
    "def test_seeds(nseeds=10):\n",
    "    # Generate 10 random integers between 1 and 10^10\n",
    "    random_nums = np.random.randint(1, int(1e5) + 1, size=nseeds)\n",
    "    print(random_nums)\n",
    "    results = []\n",
    "    for s in random_nums:\n",
    "        seed_fn(s)\n",
    "        model = simple_gnn_gcn(hidden_channels=60).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.01) \n",
    "        x_train, y_train, loss_train = training_loop(model, train_files, loss_fn, optimizer, epochs=100)\n",
    "        x_val, y_val, loss_val = validation_fn(model, valid_files, loss_fn, device)\n",
    "        # Performance metrics\n",
    "        mse = mean_squared_error(y_val, x_val)\n",
    "        r2 = r2_score(y_val, x_val)\n",
    "        # Append results\n",
    "        results.append({'seed': s, \n",
    "                        'val_mse': round(mse, 4),\n",
    "                        'val_r2': round(r2, 4),\n",
    "                        'mean_trloss': round(np.mean(loss_train), 4)\n",
    "                })\n",
    "        # Clean up GPU memory\n",
    "        del model\n",
    "        del optimizer\n",
    "        torch.cuda.empty_cache()  # Clear GPU cache\n",
    "    return results\n",
    "\n",
    "tmp = test_seeds(nseeds=5)      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5aaeda",
   "metadata": {},
   "source": [
    "## Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section: Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def loss_plotter(loss_epochs = None, epochs = None):\n",
    "    # After collecting your data\n",
    "    y = np.round(loss_epochs, 3)\n",
    "    x = list(range(0, epochs))\n",
    "    # Create scatter plot\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.plot(x, y, alpha=0.5)\n",
    "    # Add perfect prediction line (y=x)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    ymin = min(y) \n",
    "    plt.ylim(ymin, max(y))\n",
    "    plt.xlim(0, max(x))\n",
    "    return fig\n",
    "\n",
    "fig = loss_plotter(loss_epochs, epochs)\n",
    "fig.savefig('/mnt/data/sur/users/mrivera/Plots/4379fd40-9f0a-loss.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c434816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_plotter(preds = None, tgts = None, path = None ):\n",
    "    # After collecting your data\n",
    "    preds = np.concatenate(preds)  # predictions\n",
    "    tgts = np.concatenate(tgts)  # targets\n",
    "    # Create scatter plot\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(preds, tgts, alpha=0.5)\n",
    "   # Add perfect prediction line (y=x)\n",
    "    plt.plot([0,  np.max(tgts)], [0,  np.max(tgts)], 'r--', label='Perfect prediction')\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('True Values')\n",
    "    plt.title('Predictions vs True Values')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(0, max(tgts))\n",
    "    plt.xlim(0, max(tgts))\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
