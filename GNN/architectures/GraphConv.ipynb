{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ff921d0",
   "metadata": {},
   "source": [
    "This file was created for running pytorch learning with CUDA.\n",
    "\n",
    "## Documentation\n",
    "+ [ModuleList](https://docs.pytorch.org/docs/stable/generated/torch.nn.ModuleList.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a6620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION: Define-GNN\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class model(nn.Module):\n",
    "    def __init__(self,  hidden_channels=64):\n",
    "        super().__init__()\n",
    "        self.conv1 = GraphConv(1, hidden_channels) \n",
    "        self.conv2 = GraphConv(hidden_channels, 1)\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_weights\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = torch.sigmoid(x)  # Outputs between 0-1\n",
    "        return x  # [num_nodes]\n",
    "\n",
    "\n",
    "def seed_fn(seed=42):\n",
    "    # Set ALL seeds for full reproducibility\n",
    "    torch.manual_seed(seed)                 # Seed CPU \n",
    "    torch.cuda.manual_seed(seed)            # Seed GPU\n",
    "    np.random.seed(seed)                    # Seed numpy\n",
    "    random.seed(seed)                       # Seed python random\n",
    "    torch.backends.cudnn.deterministic = True   # Ensure deterministic behavior\n",
    "    torch.backends.cudnn.benchmark = False \n",
    "\n",
    "\n",
    "def loss_plotter(loss_epochs = None, epochs = None):\n",
    "    # After collecting your data\n",
    "    y = np.round(loss_epochs, 10)\n",
    "    x = list(range(0, epochs))\n",
    "    # Create scatter plot\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    # y = np.log1p(y)  # Log scale for better visualization\n",
    "    plt.plot(x, y, alpha=0.5)\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout() \n",
    "    plt.ylim(0, max(y))\n",
    "    plt.xlim(0, max(x))\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ecb33b",
   "metadata": {},
   "source": [
    "# Simple Model training\n",
    "\n",
    "This model only has 2 layers (input and output). This is the model we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5133bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from torch_geometric.loader import DataLoader\n",
    "import time\n",
    "import random\n",
    "import torch \n",
    "\n",
    "def training_loop(model, dat_batched, loss_fn, optimizer, epochs=100):\n",
    "    model.train()\n",
    "    # Empty lists for predictions, targets, loss at each epoch\n",
    "    loss_history  =  []\n",
    "    total_elapsed = 0\n",
    "    for iter in range(1, epochs+1):\n",
    "        start = time.time()\n",
    "        epoch_loss = 0\n",
    "        for path in dat_batched:\n",
    "            data = torch.load(path, weights_only=False)          \n",
    "            loader = DataLoader(data, batch_size=50, shuffle=True)\n",
    "            for batch in loader:\n",
    "                batch = batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = model(batch)\n",
    "                loss = loss_fn(out, batch.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()   # Accumulate loss\n",
    "        # Section: Best loss\n",
    "        best_loss = float('inf') if iter == 1 else best_loss\n",
    "        best_loss = min(best_loss, epoch_loss)\n",
    "        best_epoch = iter if best_loss == epoch_loss else best_epoch\n",
    "        # Append epoch loss to history\n",
    "        loss_history.append(epoch_loss)\n",
    "        elapsed = time.time() - start\n",
    "        total_elapsed += elapsed\n",
    "        print(f\"Epoch {iter}: Loss = {loss},  Elapsed time: {elapsed:.2f}\")\n",
    "    # Summary\n",
    "    print(f'>> the total elapsed time with {epochs} epochs is {total_elapsed:.2f} seconds ( {total_elapsed/60:.2f} minutes)')      \n",
    "    return  loss_history, best_loss, best_epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacb2ad0",
   "metadata": {},
   "source": [
    "## Simple model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54764756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "def validation_fn(model, files, loss_fn, device):\n",
    "    model.eval()\n",
    "    # Assign variables\n",
    "    val_loss, total_graphs = 0, 0\n",
    "    true_idx, pred_idx = [], []\n",
    "    with torch.no_grad():\n",
    "        for path in files:\n",
    "            data_list = torch.load(path, weights_only=False)\n",
    "            total_graphs += len(data_list)\n",
    "            # Batch all graphs together\n",
    "            batch = Batch.from_data_list(data_list).to(device)\n",
    "            # Forward pass\n",
    "            out = model(batch)  # shape: [num_graphs * 30, features] or [num_graphs * 30]\n",
    "            loss = loss_fn(out, batch.y)\n",
    "            val_loss += loss.item()\n",
    "            # Process each graph separately\n",
    "            for i in range(batch.num_graphs):\n",
    "                mask = batch.batch == i  # nodes belonging to graph i\n",
    "                graph_y = batch.y[mask]  # 30 targets per graph\n",
    "                graph_out = out[mask]    # 30 predictions per graph  \n",
    "                # Get max index in 0-based\n",
    "                true_idx.append(torch.argmax(graph_y).item() + 1)\n",
    "                pred_idx.append(torch.argmax(graph_out).item() + 1)\n",
    "    return true_idx, pred_idx, val_loss, total_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb28fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(true, preds):\n",
    "    true = true_idx\n",
    "    preds = pred_idx\n",
    "    result = [a == b for a, b in zip(true, preds)]\n",
    "    correct = sum(result)\n",
    "    accuracy = (correct / len(true)) * 100\n",
    "    return(f'>> Validation Accuracy: {accuracy:.2f}% ({correct}/{len(true)})')\n",
    "\n",
    "# Declare data paths\n",
    "directory = '/home/mriveraceron/data/exp_20251125'\n",
    "train_files = glob.glob(f'{directory}/TrainBatch_*.pt')\n",
    "valid_files = glob.glob(f'{directory}/ValBatch_*.pt')\n",
    "\n",
    "# Loss function and device\n",
    "loss_fn = nn.MSELoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Set seed and run model\n",
    "seed_fn(38)\n",
    "model = model(hidden_channels=60).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "mod1_loss, mod1_BestLoss, mod1_BestEpoch = training_loop(model, train_files, loss_fn, optimizer, epochs=200)\n",
    "true_idx, pred_idx, mod1_ValLoss, total_graphs = validation_fn(model, train_files, loss_fn, device)\n",
    "pf1 = accuracy(true_idx, pred_idx)\n",
    "\n",
    "# Plot the loss over epochs\n",
    "fig = loss_plotter(mod1_loss, epochs = 200)\n",
    "fig.savefig('/home/mriveraceron/glv-research/plots/3December-loss.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2b8ce",
   "metadata": {},
   "source": [
    "# Understanding pytorch Dataloader\n",
    "\n",
    "\n",
    "The following code demonstrates how to get the maximum value of the y tensor for each individual sample (graph) when using DataLoader for batching in PyTorch Geometric.\n",
    "\n",
    "## Problem 1\n",
    "When graphs are batched together using DataLoader, all node features and labels are concatenated. The `batch` vector indicates which nodes belong to which graph, but we need to extract the maximum y value for each original graph separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "from torch_geometric.nn import global_max_pool\n",
    "\n",
    "# Original Data objects:\n",
    "dataset = []\n",
    "for i in range(5):\n",
    "    data = Data(x=torch.randn(10, 1), y=torch.tensor([1, 1, 100, 1, 1, 1, 1, 1, 1, (i+1)*(10**(i+1))]))\n",
    "    dataset.append(data)\n",
    "\n",
    "# Create DataLoader\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# How batches work\n",
    "batch = Batch.from_data_list(dataset)                   # Create batch\n",
    "print(f\"batch.batch: {batch.batch}\")                    # To which graph each node belongs \n",
    "print(f\"batch.y: {batch.y}\")                            # All y values concatenated\n",
    "print(f\"Total nodes: {batch.num_nodes}\")                # Number of nodes in the batch\n",
    "print(f\"Number of graphs: {batch.num_graphs}\")          # Number of graphs in the batch\n",
    "\n",
    "# Iterate through batches\n",
    "vector = []\n",
    "for batch in loader:\n",
    "    print(f\"Graphs per batch: {batch.num_graphs}\")\n",
    "    print(f\"Total nodes in batch: {batch.num_nodes}\")   # x are the nodes\n",
    "    print(f\"x (nodes) shape: {batch.x.shape}\")\n",
    "    print(f\"y shape: {batch.y.shape}\")\n",
    "    print(f\"batch vector: {batch.batch}\")\n",
    "    # print(f'testing: {batch.y.unsqueeze(-1)}')\n",
    "    max_y_per_graph = global_max_pool(batch.y.unsqueeze(-1), batch.batch).squeeze(-1)\n",
    "    vector.extend( max_y_per_graph.tolist() )\n",
    "    print(f\"Max y per graph: {max_y_per_graph}\")\n",
    "    print(\"---\")\n",
    "\n",
    "sorted(vector)\n",
    "\n",
    "\n",
    "# How does unsqueeze work?\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "x.size()\n",
    "x = torch.unsqueeze(x, -1)\n",
    "x.size()\n",
    "x = torch.squeeze(x, -1)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a512879",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "When batching graphs, all node features and targets are concatenated into a single large tensor. To aggregate node-level predictions back to graph-level predictions, we use the `scatter` function, which groups nodes by their graph assignment using the `batch.batch` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96112a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = torch.tensor([0, 1, 0, 2, 1, 2])\n",
    "data = torch.tensor([10, 20, 30, 40, 50, 60])\n",
    "scatter(data, index, dim=0, reduce='max')  # Should be [30, 50, 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3b54f8",
   "metadata": {},
   "source": [
    "## Poblem 3\n",
    "\n",
    "We are interested in obtaining the index of the ith element whose value is the maximum in the tensor. We can do such with `torch.argmax`. We can do such in individual tensors but when using batches from Dataloader we will use a different approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2beea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Use on individual tensor\n",
    "a = torch.randn(4)\n",
    "torch.argmax(a)\n",
    "\n",
    "# Usage on batched data\n",
    "dataset = []\n",
    "for i in range(5):\n",
    "    data = Data(x=torch.randn(10, 1), y=torch.randn(10) )\n",
    "    dataset.append(data)\n",
    "\n",
    "# Create DataLoader\n",
    "batch = Batch.from_data_list(dataset).to(device)\n",
    "print(f'the number of graphs are {batch.num_graphs}')\n",
    "\n",
    "# Iterate through batches\n",
    "vector = []\n",
    "for i in range(batch.num_graphs):\n",
    "    mask = batch.batch == i  # nodes belonging to graph i\n",
    "    graph_y = batch.y[mask]  # 30 targets per graph\n",
    "    idx_max = torch.argmax(graph_y).cpu().numpy().item()\n",
    "    vector.append( idx_max + 1 )\n",
    "vector\n",
    "\n",
    "for d in dataset:\n",
    "    idx_max = torch.argmax(d.y).cpu().numpy().item()\n",
    "    print(f'maximum index : {idx_max + 1}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8b881b",
   "metadata": {},
   "source": [
    "# Multiple seeds testing\n",
    "\n",
    "As initial weight matrix is completely random, testing for multiple seeds and the choosing of the best one has to be tested. For this purpose we generate some seeds and test for improvement in loss over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad14c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def seed_fn(seed=42):\n",
    "    # Set ALL seeds for full reproducibility\n",
    "    torch.manual_seed(seed)                 # Seed CPU \n",
    "    torch.cuda.manual_seed(seed)            # Seed GPU\n",
    "    np.random.seed(seed)                    # Seed numpy\n",
    "    random.seed(seed)                       # Seed python random\n",
    "    torch.backends.cudnn.deterministic = True   # Ensure deterministic behavior\n",
    "    torch.backends.cudnn.benchmark = False \n",
    "\n",
    "def test_seeds(nseeds=10):\n",
    "    # Generate 10 random integers between 1 and 10^10\n",
    "    random_nums = np.random.randint(1, int(1e5) + 1, size=nseeds)\n",
    "    print(random_nums)\n",
    "    results = []\n",
    "    for s in random_nums:\n",
    "        seed_fn(s)\n",
    "        model = simple_gnn_gcn(hidden_channels=60).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.01) \n",
    "        x_train, y_train, loss_train = training_loop(model, train_files, loss_fn, optimizer, epochs=100)\n",
    "        x_val, y_val, loss_val = validation_fn(model, valid_files, loss_fn, device)\n",
    "        # Performance metrics\n",
    "        mse = mean_squared_error(y_val, x_val)\n",
    "        r2 = r2_score(y_val, x_val)\n",
    "        # Append results\n",
    "        results.append({'seed': s, \n",
    "                        'val_mse': round(mse, 4),\n",
    "                        'val_r2': round(r2, 4),\n",
    "                        'mean_trloss': round(np.mean(loss_train), 4)\n",
    "                })\n",
    "        # Clean up GPU memory\n",
    "        del model\n",
    "        del optimizer\n",
    "        torch.cuda.empty_cache()  # Clear GPU cache\n",
    "    return results\n",
    "\n",
    "tmp = test_seeds(nseeds=5)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c434816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_plotter(preds = None, tgts = None, path = None ):\n",
    "    # After collecting your data\n",
    "    preds = np.concatenate(preds)  # predictions\n",
    "    tgts = np.concatenate(tgts)  # targets\n",
    "    # Create scatter plot\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(preds, tgts, alpha=0.5)\n",
    "   # Add perfect prediction line (y=x)\n",
    "    plt.plot([0,  np.max(tgts)], [0,  np.max(tgts)], 'r--', label='Perfect prediction')\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('True Values')\n",
    "    plt.title('Predictions vs True Values')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(0, max(tgts))\n",
    "    plt.xlim(0, max(tgts))\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
