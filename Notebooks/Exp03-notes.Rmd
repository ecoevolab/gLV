---
title: "Exp03-D25M02"
author: "Manuel Rivera"
output: html_document
date: "2025-02-25"
---
## Compare observed probabilities vs expected probabilities.

```{r}
#` Load parameters table
params_table <- data.table::fread("/home/rivera/Cluster/glv-research/Data/Exp03-D25M02.tsv")

# For cluster:
# params_table <- data.table::fread("/mnt/atgc-d3/sur/users/mrivera/glv-research/Data/Exp03-D25M02.tsv")

head(params_table)
```

Regenerate the parameters for each simulation with the function `regenerate`, calculate the observed null and negative probability.
```{r}
# The following function is an updated version of the code to generate parameters based on the `parameters_table`.  
# More information can be found in the `Forge-gLV-Parameters.R` file.  
source("/home/rivera/Cluster/glv-research/GIT-gLV/Forge-gLV-Parameters.R")
# For cluster:
# source("/mnt/atgc-d3/sur/users/mrivera/glv-research/GIT-gLV/Forge-gLV-Parameters.R")

  
# Calculate the observed null and negative probability.
tmp <-  lapply(1:nrow(params_table), function(i) {
    
    # cat("Starting simulation ", i,"...\n")
    p <- regenerate(params_table[i,]) # Regenerate the parameters
  
    # Get non-diagonal elements in one step
    non_diag_elements <- p$M[row(p$M) != col(p$M)]
    
    # Efficiently compute proportions using mean (avoids explicit sums)
    p_neg_obs <- mean(non_diag_elements < 0)
    p_nint_obs <- mean(non_diag_elements == 0)
    
    # Return named vector
    return(c(p_neg_obs = p_neg_obs, 
             p_neg_noint = p_nint_obs))
})

res <- unlist(tmp)
tmp_df <- as.data.frame(matrix(res, ncol = 2, byrow = TRUE))
colnames(tmp_df) <- unique(names(res))

head(tmp_df)
```

Select only the columns of interest from `params_table`,  adds the counts of true negative and null interactions (`tmp_df`),  calculate the error between Observed and Expected values.
```{r}
suppressPackageStartupMessages(library(dplyr))
error.df <- params_table %>%
  select(p_noint, p_neg, n_species) %>% # select columns of interest
  mutate(tmp_df) %>%  # Negative and Null oserved probabilities 
  group_by(p_neg, p_noint) %>% 
 summarise(
  Total_specs = sum(n_species), # Calculate total number of species
  Sims_done = n(),  # Count total simulations done with the combination of parameters
  er_noint = p_neg_noint - p_noint, 
  er_negs = p_neg_obs - p_neg,
  .groups = "drop"
)

head(error.df)
```

Create graph:
```{r}
suppressPackageStartupMessages(library(ggplot2))

p1 <- error.df %>%
  ggplot(aes(x = er_negs)) +
  facet_grid(p_noint ~ p_neg) +
  geom_histogram(bins = 5) + 
  geom_vline(xintercept = 0, col = "red") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90)) +
  scale_x_continuous(sec.axis = dup_axis(name = "p_neg")) +
  scale_y_continuous(sec.axis = dup_axis(name = "p_noint"))
p1
```

Save the graph
```{r}
ggsave("/home/rivera/Pictures/glv-Graphs/Exp03-error_in_p_neg.svg", width = 6, height = 6)
```

## Generate the simulations with ODE and miaSim

Load parameters table
```{r Load.parameters.table, eval = FALSE}

# Load Parameters table
params_table <- data.table::fread("/mnt/atgc-d3/sur/users/mrivera/glv-research/Data/Exp03-D25M02.tsv")

# Source function to regenerate parameters
source("/mnt/atgc-d3/sur/users/mrivera/glv-research/GIT-gLV/Forge-gLV-Parameters.R")
print(regenerate)
```

Declare a function for the ODE solver with a relative tolerance of 1e-06 and an absolute tolerance of 1e-06. 
+ The first column is removed because it records the generations (from 0 to times).
+ The data frame is also transposed so that columns represent time instead of rows.
```{r gLV.ODE.solver, eval = FALSE}
ode.simulate <- function (times, params) {
  
  # Define the equation
  glv_model <- function(t, x0, params) {
    r <- params$mu         # Growth rate vector
    A <- params$M          # Interaction matrix
    
    # Compute dx/dt for each species
    dx <- x0 * (r + A %*% x0)
    list(dx)
  }
  
  time_seq <- seq(1, times, by = 1)  # Define the time sequence
  
  # Get solution
  results <- tryCatch(
    R.utils::withTimeout(deSolve::ode(y = params$x0, times = time_seq, func = glv_model, 
                          parms = params,
                          method = "ode45",
                          rtol = 1e-06, 
                          atol = 1e-06),
    timeout = 600), 
    error = function(e) {
      message(">> Simulation failed... skipping")
      return(NULL) # Return NULL instead of an NA matrix
    })
  
  
  # Remove the first column (`time`) and transpose it so columns represent generations
  # Check for valid output and return transposed results
  if (!is.null(results) && ncol(results) > 1) {
    return(t(results[, -1]))
  } else {
    return(matrix(NA, nrow = nrow(params$M), ncol = times)) # Return properly shaped NA matrix
  }
}
```

miaSim delcares the Generalized Lotka-Volterra equation as it follows:
```{r}
suppressPackageStartupMessages(library(miaSim))

 getAnywhere("glvModel")
```


Split the parameters in `n` chunks for parallelizing.
```{r, eval = FALSE}
suppressPackageStartupMessages(library(parallel))

num_cores <- detectCores() - 1  # Use one less than the total number of cores
cat("The number of cores that will be used are: ", num_cores, "\n")

split_table <- function(df, n_chunks) {
  split(df, cut(seq_len(nrow(df)), breaks = n_chunks, labels = FALSE))
}

chunks <- split_table(params_table, num_cores)
```

Generate each worker a directory for saving its outputs and avoid race condition
```{r, eval = FALSE}
# Generate workers directories
# mias_dir <- "/mnt/atgc-d3/sur/users/mrivera/glv-research/Results/Exp03-D25M02/Simulate_miaSim"
ode_dir <- "/mnt/atgc-d3/sur/users/mrivera/glv-research/Results/Exp03-D25M02/Simulate_ODE"

# Function to create main and worker directories
create_dirs <- function(main_dir, num_cores) {
  if (!dir.exists(main_dir)) dir.create(main_dir, recursive = TRUE)
  
  # Create worker directories
  worker_dirs <- file.path(main_dir, paste0("worker_", seq_len(num_cores)))
  invisible(lapply(worker_dirs, dir.create, showWarnings = FALSE))
  
  return(worker_dirs)
}

# Create directories for both simulations
# workers_mia <- create_dirs(mias_dir, num_cores)
workers_ODE <- create_dirs(ode_dir, num_cores)
```

The following function wraps multiple processes related to the Generalized Lotka-Volterra (gLV) model. It performs the following tasks:

1. **Generate gLV parameters** `regenerate` function 
2. **Run the simulation**  `ode.simulate` function 
3. **Save the simulation output**  
4. **Calculate NA values**  
5. **Save the final results**
```{r, eval=FALSE}
parallel.sims <- function(index, path_ODE) {
  
  # Generate parameters
  params <- regenerate(index)
  
  # Run simulation
  output_ode <- ode.simulate(times = 700, params)
  
  # Define paths
  id <- index$id
  save_ode <- file.path(path_ODE, paste0("O_", id, ".tsv"))
  
  # Calculate NAs
  Total.NAs <- sum(is.na(output_ode))
  
  # Save simulation
  utils::write.table(output_ode, file = save_ode, sep = "\t", row.names = FALSE, col.names = TRUE)
  
  return(c(id = id,
           Total.NAs = Total.NAs)
  )
}
```

Parallelize simulations with `parallel::mclapply` function.
```{r, eval=FALSE}
# ==== Parallelize it ====
tictoc::tic("Section 3: Run simulations using the parallel package")

NAs_vecs <- parallel::mclapply(1:num_cores, function(core_id) {
  
  message("Starting worker ", core_id, "....\n")
  
  core_chunk <- chunks[[core_id]]  # rows assigned to this core
  
  # cat("\nODE path", workers_ODE[core_id], "\n")
  
  na.vec <- lapply(1:nrow(core_chunk), function(i) {
    parallel.sims(core_chunk[i, ], 
            path_ODE = workers_ODE[core_id])
  })
  
  message("Ending worker ", core_id, "....\n")
  
  return(na.vec)
  
}, mc.cores = num_cores)
toc() # For section 3
```

Get number of NAs and save them.
```{r, eval=FALSE}
# ==== Get NAs number on simulations====
tictoc::tic("Section 4: Count total number of NAs")
NAs.counts <- unlist(NAs_vecs)
counts_df <- as.data.frame(matrix(NAs.counts, ncol = 2, byrow = TRUE))
colnames(counts_df) <- unique(names(NAs.counts))

# Save Parameters as TSV
save.path = "/mnt/atgc-d3/sur/users/mrivera/glv-research/Results/Exp03-D25M02/Nas-counting.tsv"
data.table::fwrite(x = counts_df, file = save.path, sep = "\t")
toc() # For section 4
```

Create symbolic links for each worker
```{r, eval=FALSE}
# ==== Create symbolic links====
tictoc::tic("Section 5: Generate symbolic links")

source("/mnt/atgc-d3/sur/users/mrivera/glv-research/GIT-gLV/forge_symlinks.R")
# Define source and target directories
source_path <- "/mnt/atgc-d3/sur/users/mrivera/glv-research/Results/Exp03-D25M02/Simulate_ODE"
target_path <- "/mnt/atgc-d3/sur/users/mrivera/glv-research/Results/Exp03-D25M02/Simulate_ODE/Unified"
generate_symlinks(source_path = source_path, target_path = target_path)

toc() # For section 5
```

# Conclussions
- miaSim generates the time sequence using another parameter `t_step` which is used for an interval between simulation steps. It can be viewed with `?miaSim::.simulationTimes`

# Generate plots of failed simulations

Load parameters table and NA counting table
```{r}
# ==== Load data====
params_table <- read.delim("/home/rivera/Cluster/glv-research/Data/Exp03-D25M02.tsv", 
           sep = "\t", header = TRUE)

NA.table <- read.delim("/home/rivera/Cluster/glv-research/Results/Exp03-D25M02/Nas-counting.tsv", 
           sep = "\t", header = TRUE)
```

Join parameters by id
```{r}
# ==== Join tables====
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(plotly))

# Function to process and summarize data
process_data <- function(NA.table, params_table) {
  NA.table %>% 
    mutate(across(-1, ~ if_else(. > 0, 1, .))) %>% # Convert to 0's or 1's
    # Join parameters
    full_join(params_table %>% select(n_species, id, p_neg, p_noint), by = "id") %>%
    mutate(across(c(p_neg, p_noint), ~ round(.x, 2))) %>%
    group_by(p_neg, p_noint, n_species) %>%
    summarize(
      n_failed = sum(Total.NAs != 0, na.rm = TRUE), # Failed simulations
      n_ran = sum(Total.NAs == 0, na.rm = TRUE)) # Runned simulations
}

# Apply function to both datasets
summed_ode <- process_data(NA.table, params_table)
head(summed_ode)
```

Declare function for creating blackbox on every panel.
```{r}
#' Blackbox theme
#' 
#' ggplot2 theme that places a black margin on every
#' panel
#'
#' @param border.size Thickness of the margin.
#'
#' @return A \code{theme gg} object.
#' @export
#' @author Sur Herrera Paredes
theme_blackbox <- function(border.size = 3){
  theme(axis.text = element_text(color="black"),
        axis.title = element_text(face="bold"),
        panel.background = element_rect(color = "black",
                                        size = border.size,
                                        fill = NA),
        panel.grid = element_blank())
}
```

Generate heat map plot.
```{r}
p1 <- summed_ode %>%
  ggplot(aes(x = p_noint, y = p_neg)) + 
  facet_wrap(~ n_species) +
  geom_tile(aes(fill = n_ran), color = "black") + 
  scale_fill_gradientn(colours = c("#fee8c8", "#e34a33"), values = c(0,1)) +
  theme_blackbox()
p1
```

Save HeatMap
```{r}
ggsave("/home/rivera/Pictures/glv-Graphs/Exp03-HMrunned.svg", width = 6, height = 4)
```


# Calculate richness??

Pendiente....

